---
title: "Biases in Mixed-Effects Model GMMs"
author: "Nicolas Kuehn, Ken Campbell, Yousef Bozorgnia"
date: "`r format(Sys.time(), '%d %B, %Y')`"
output:
  html_document:
    keep_md: true
    toc: true
    toc_depth: 3
    number_sections: true
    highlight: tango
link-citations: yes
linkcolor: blue
citecolor: blue
urlcolor: blue
bibliography: /Users/nico/BIBLIOGRAPHY/BIBTEX/references.bib
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, fig.width=12,fig.height = 8, out.width = '50%', fig.show="hold",
                      fig.path = 'pictures/',
root.dir = '/Users/nico/GROUNDMOTION/PROJECTS/RESID_VAR/')
```

# Introduction

This page provides code for the simulations shown in ``Potential Biases in Empirical Ground-Motion Models by focusing on Point Estimates of Random Effects'', which highlights some biases that can occur when using point estimates of random effects/residuals in mixed effects ground-motion models.
For details, see the paper.

We use simulations from different models and/or using different data sets to illustrate potential biases.
In particular, standard deviations are underestimated when they are calculated from point estimates of random effects/residuals.
For the simulations, we randomly sample event terms, site terms, and within-event/within-site residuals from their respective distributions, and then perform regessions on the sampled data to see whether we recover get the parameters used in the simulations.
In this document, we generally do a single simulation for different cases, which typically highlight the points we want to made.
For the paper, we repeat these simulations multiple times, since due to the relative small sample size in ground-motion data sets there ca be variability from one sample to the next.

Simulation can be a pwoeful tool to gain understanding of different models [@DeBruine2021].
There exist several `R`-packages for simulation (e.g. [faux](https://debruine.github.io/faux/index.html), [simDesign](https://cran.r-project.org/web/packages/SimDesign/vignettes/SimDesign-intro.html), [simulator](https://github.com/jacobbien/simulator)), but since our models are simple, we code them up directly.

In general, a ground-motion model (GMM) can be written as
$$
Y_{es} = f(\vec{c}; \vec{x}) + \delta B_e + \delta S_s + \delta WS_{es}
$$
or in matrix form as
$$
\vec{Y} = f(\vec{c}; \mathbf{x}) + \mathbf{Z} \vec{u} + \vec{\delta WS} 
$$
where $\mathbf{Z}$ is the design matrix of the random effects.
It is importat to remember that in general the outcome of a mixed-effects regression will give point estimates of the random effects (the conditional modes),and that there is uncetainty around them.
The conditional variances of the random effects are the diagonal entries of the following matrix
$$
\psi(\hat{\vec{u}})^2 = \phi_{SS}^2 \mathbf{\Lambda} \left(\mathbf{\Lambda}^T \mathbf{Z}^T \mathbf{Z} \mathbf{\Lambda} + \mathbf{I} \right)^{-1} \mathbf{\Lambda}
$$
where $\mathbf{\Lambda}$ is the relative covariance factor [@Bates2015].
If this uncertainty is ignored, biases can occur, as we deomstrate throughut this page.
In particular, the variances of the random effects are calculated as (example for $\tau$)
$$
\hat{\tau}^2 = \frac{1}{N_E}\sum_{i = 1}^{N_E} \widehat{\delta B}_i^2 + \frac{1}{N_E}\sum_{i = 1}^{N_E} \psi(\widehat{\delta B}_i)^2 
$$
which is the sum of the variance of the point estimates plus the average conditional variance.
Hence, just esimating the variance (or standard deviation) of the point estimates will lead to an underestmation.

## Set up

Load required libraries, and define some plot options for `ggplot2`.

```{r load-libraries, warning=FALSE, message=FALSE, echo=TRUE}
library(ggplot2)
library(lme4)
library(cmdstanr)
library(posterior)
library(bayesplot)
library(tidyverse)
library(INLA)
library(matrixStats)
library(latex2exp)
```

```{r cmdstan-path, echo=FALSE}
set_cmdstan_path('/Users/nico/GROUNDMOTION/SOFTWARE/cmdstan-2.33.1')
```

``` {r plot-options}
theme_set(theme_bw() + theme(
  axis.title = element_text(size = 30),
  axis.text = element_text(size = 20),
  plot.title = element_text(size = 30),
  legend.text = element_text(size = 20),
  legend.title = element_text(size = 20),
  legend.key.width = unit(1, "cm"),
  legend.box.background = element_rect(colour = "black"),
  panel.grid = element_line(color = "gray",linewidth = 0.75)
))

breaks <- 10^(-10:10)
minor_breaks <- rep(1:9, 21)*(10^rep(-10:10, each=9))

lw <- 1.5 # linewidth
sp <- 4 # pointsize
```

## Example

We start with an example using real data, just to get familiar with the concepts and code.
In later sections, we use simulations, which make it easy to compare the results from a regression to the true values of the parameters.
We use the Ialian data from the ITA18 GMM (@Lanzano2018, see also @Caramenti2022), and perform a regression on peak ground acceleration (PGA), using the functional form of ITA18.

First, we read in the data and prepare a data frame for the regression.
In total, there are 4784 records from 137 events and 923 stations.

``` {r example-it-data}
data_it <- read.csv(file.path('./Git/MixedModels_Biases/','/data','italian_data_pga_id_utm_stat.csv'))

# Set linear predictors
mh = 5.5
mref = 5.324
h = 6.924
attach(data_it)
b1 = (mag-mh)*(mag<=mh)
b2 = (mag-mh)*(mag>mh)
c1 = (mag-mref)*log10(sqrt(JB_complete^2+h^2))
c2 = log10(sqrt(JB_complete^2+h^2))
c3 = sqrt(JB_complete^2+h^2)
f1 = as.numeric(fm_type_code == "SS")
f2 = as.numeric(fm_type_code == "TF")
k = log10(vs30/800)*(vs30<=1500)+log10(1500/800)*(vs30>1500)
y = log10(rotD50_pga)
detach(data_it)

n_rec <- length(b1)
eq <- data_it$EQID
stat <- data_it$STATID
n_eq <- max(eq)
n_stat <- max(stat)
n_rec <- nrow(data_it)

data_reg <- data.frame(Y = y,
                       M1 = b1,
                       M2 = b2,
                       MlogR = c1,
                       logR = c2,
                       R = c3,
                       Fss = f1,
                       Frv = f2,
                       logVS = k,
                       eq = eq,
                       stat = stat,
                       intercept = 1
)
print(paste0('Number of records: ',n_rec,'; number of events: ',n_eq,'; number of stations: ',n_stat))
```

Now we fit the model.
We fit the model using `lmer`, `inla`, and using Stan via `cmdstanr`.
The Stan code can be found at <https://github.com/nikuehn/MixedModels_Biases/tree/main/stan>.


``` {r example-regression, cache = TRUE}
##################
# fit using lmer

fit_lmer <- lmer(Y ~ M1 + M2 + MlogR + logR + R + Fss + Frv + logVS + (1|eq) + (1|stat), data_reg)

tmp <- as.data.frame(VarCorr(fit_lmer))$sdcor
phi_s2s_lmer <- tmp[1]
tau_lmer <- tmp[2]
phi_ss_lmer <- tmp[3]

deltaB <- ranef(fit_lmer)$eq$`(Intercept)`
deltaS <- ranef(fit_lmer)$stat$`(Intercept)`
sd_deltaB <- as.numeric(arm::se.ranef(fit_lmer)$eq)
sd_deltaS <- as.numeric(arm::se.ranef(fit_lmer)$stat)
deltaWS <- data_reg$Y - predict(fit_lmer)
sd_deltaWS <- sqrt(sd_deltaB[eq]^2 + sd_deltaS[stat]^2) # approximately

##################
# fit using Inla
# priors for standard deviation paramters
prior_prec_tau    <- list(prec = list(prior = 'pc.prec', param = c(0.3, 0.01)))
prior_prec_phiS2S    <- list(prec = list(prior = 'pc.prec', param = c(0.3, 0.01))) 
prior_prec_phiSS    <- list(prec = list(prior = 'pc.prec', param = c(0.3, 0.01))) 

form <- Y ~ M1 + M2 + MlogR + logR + R + Fss + Frv + logVS +
  f(eq, model = "iid", hyper = prior_prec_tau) + 
  f(stat, model = "iid",hyper = prior_prec_phiS2S)

fit_inla <- inla(form, 
                 data = data_reg,
                 family="gaussian",
                 control.family = list(hyper = prior_prec_phiSS)
)

sd_deltaS_inla <-fit_inla$summary.random$stat$sd
sd_deltaB_inla <-fit_inla$summary.random$eq$sd
sd_deltaWS_inla <- fit_inla$summary.fitted.values$sd

##################
# fit using Stan
mod <- cmdstan_model(file.path('./Git/MixedModels_Biases/', 'stan', 'gmm_full_qr.stan'))
data_list <- list(
  N = n_rec,
  NEQ = n_eq,
  NSTAT = n_stat,
  K = 9,
  Y = as.numeric(data_reg$Y),
  X = data_reg[,c("M1", "M2", "MlogR", "logR", "R", "Fss", "Frv", "logVS")], # design matrix
  eq = eq,
  stat = stat,
  alpha = c(1,1,1)
)

fit_stan <- mod$sample(
  data = data_list,
  seed = 8472,
  chains = 4,
  iter_sampling = 200,
  iter_warmup = 200,
  refresh = 100,
  max_treedepth = 10,
  adapt_delta = 0.8,
  parallel_chains = 2,
  show_exceptions = FALSE
)
draws <- fit_stan$draws()

sd_deltaB_stan <- colSds(subset(as_draws_matrix(draws), variable = 'eqterm'))
sd_deltaS_stan <- colSds(subset(as_draws_matrix(draws), variable = 'statterm'))
sd_deltaWS_stan <- colSds(subset(as_draws_matrix(draws), variable = 'resid'))
```

The estimated standard deviations are very similar between the three methods (we have used relatively weak priors, so their influence is not very strong).
For Inla, we transform the mean estimate of the precisions into an estimate of the standard deviations, which is technicaly not correct, but for the sake of smplicity we keep it.
The difference is small.
Note that for the Bayesian models (Inla and Stan), the full output is not just a point estimate of $\phi_{SS}$, $\tau$, and $\phi_{S2S}$, but the full posterior distribution.

``` {r example-comp-sd}
df <- data.frame(inla = 1/sqrt(fit_inla$summary.hyperpar$mean),
                 lmer = c(phi_ss_lmer, tau_lmer, phi_s2s_lmer),
                 stan = colMeans(subset(as_draws_matrix(draws), variable = c('phi_ss','tau','phi_s2s'))),
                 row.names = c('phi_ss','tau','phi_s2s'))
knitr::kable(df, digits = 5, row.names = TRUE,
             caption = "Comparison of standard deviation estimates.")
```
The coefficient estimates are also very close.

``` {r example-comp-coeff}
df <- data.frame(inla = fit_inla$summary.fixed$mean,
                 lmer = fixef(fit_lmer),
                 stan = colMeans(subset(as_draws_matrix(draws), variable = c('^c\\['), regex = TRUE)))
knitr::kable(df, digits = 5, row.names = TRUE,
             caption = "Comparison of standard coefficient estimates.")
```

Below we plot the standard deviations of the random effects (conditional standard deviations for `lmer`, standard deviations of the posterior distribution for the Bayesian models) against number of records per event/station.
In general, they are similar between all three fits.
We see larger standard deviations of the event terms for the Bayesian models for large magnitudes, which is due to the fact that uncertainty due to coefficients is included, which is larger for large magnitudes.

``` {r example-plot-se, out.width = '100%', fig.width=16}
p1 <- data.frame(unique(data_it[,c('EQID','mag')]),
                 lmer = sd_deltaB,
                 inla = sd_deltaB_inla,
                 stan = sd_deltaB_stan,
                 nrec = as.numeric(table(eq))) |>
  pivot_longer(c(lmer, inla, stan)) %>%
  ggplot() +
  geom_point(aes(x = nrec, y = value, color = name, size = mag)) +
  scale_x_log10(breaks = breaks, minor_breaks = minor_breaks) +
  ylim(c(0,0.125)) +
  labs(x = 'number of records per event', y = TeX("$\\psi(\\widehat{\\delta B})$")) +
  guides(color = guide_legend(title=NULL), size = guide_legend(title = 'M')) +
  theme(legend.position = c(0.85,0.75))

p2 <- data.frame(unique(data_it[,c('STATID','vs30')]),
           logvs = unique(data_reg[,c('stat','logVS')])[,2],
           lmer = sd_deltaS,
           inla = sd_deltaS_inla,
           stan = sd_deltaS_stan,
           nrec = as.numeric(table(stat))) |>
  pivot_longer(c(lmer, inla, stan)) %>%
  ggplot() +
  geom_point(aes(x = nrec, y = value, color = name, size = vs30)) +
  scale_x_log10(breaks = breaks, minor_breaks = minor_breaks) +
  ylim(c(0,0.18)) +
  labs(x = 'number of records per station', y = TeX("$\\psi(\\widehat{\\delta S})$")) +
  guides(color = guide_legend(title=NULL), size = guide_legend(title = 'VS30')) +
  theme(legend.position = c(0.85,0.75))

patchwork::wrap_plots(p1,p2)
```
Below we compare the standard deviations for $\delta WS$.
For `lmer`, this is an approximation, calculated as $\psi(\widehat{\delta WS})^2 = \psi(\widehat{\delta B})^2 + \psi(\widehat{\delta S})^2$.
At larger values of $\psi(\widehat{\delta WS})$, the values from `lmer` are larger compared to the ones from Inla or Stan, which is probably due to some correlations between (estimated) event terms and site terms.
These corelations are implicitly taken into account in the Bayesian models.

``` {r example-plot-se2}
data.frame(inla = sd_deltaWS_inla, 
           lmer = sd_deltaWS,
           stan = sd_deltaWS_stan) %>%
  pivot_longer(!inla) %>%
  ggplot() +
  geom_point(aes(x = inla, y = value, color = name), size = 4) +
  geom_abline(color = 'black', linewidth = 1.5) +
  lims(x = c(0.03,0.21), y = c(0.03, 0.21)) +
  labs(x = TeX("$\\psi(\\widehat{\\delta WS}_{inla})$"),
       y = TeX("$\\psi(\\widehat{\\delta WS})$")) +
  guides(color = guide_legend(title=NULL))
```

We now calculate the conditional standard deviations of the random effects from the `lmer` fit according to Equation (3) of the paper, which makes use of the design matrix of the random effects $\mathbf{Z}$, and the relative covariance factor $\mathbf{\Lambda}$.

``` {r example-calc-se}
Z <- getME(fit_lmer, 'Z') #sparse Z design matrix
lambda <- getME(fit_lmer, 'Lambda')

V <- sigma(fit_lmer)^2 * lambda %*% solve((t(lambda) %*% t(Z) %*% Z %*% lambda + diag(n_eq + n_stat))) %*% lambda

# station entries are first
print(c(sum((arm::se.ranef(fit_lmer)$stat)^2 / diag(V)[1:n_stat]),
        sum((arm::se.ranef(fit_lmer)$eq)^2 / diag(V)[(n_stat + 1):(n_eq + n_stat)])))
```

# Simulations using CB14 Data

We now turn to simulations to show how biases can occur when the uncertainty of random effects (event and site terms) as well as residuals is neglected.
We first focus on standard deviations, which are underestimated when estimated from point estimates.
This becomes a problem when standard deviations are modeled as heteroscedastic, e.e. dependent on predictor variables such as magnitude and/or distance.

We illustrate the underestimation of standard deviations on the WUS data from the GMM of @Campbell2014.
In total, there are 12482 records from 274 events and 1519 stations.

```{r read-data-cb, out.width = '100%', fig.width=16}
data_reg <- read.csv(file.path('./Git/MixedModels_Biases/','/data','data_cb.csv'))
print(dim(data_reg))
print(head(data_reg))

p1 <- ggplot(data_reg) +
  geom_point(aes(x = Rrup, y = M)) +
  scale_x_log10(breaks = breaks, minor_breaks = minor_breaks)
p2 <- ggplot(unique(data_reg[,c('eqid','M')])) +
  geom_histogram(aes(x = M))
patchwork::wrap_plots(p1, p2)
```

```{r prepare-data-cb}
n_rec <- nrow(data_reg)
n_eq <- max(data_reg$eq)
n_stat <- max(data_reg$stat)

eq <- data_reg$eq
stat <- data_reg$stat

mageq <- unique(data_reg[,c('eq','M')])$M # event-specific magnitude
magstat <- unique(data_reg[,c('stat','M_stat')])$M_stat # station-specific magnitude

print(paste0('Number of records: ',n_rec,'; number of events: ',n_eq,'; number of stations: ',n_stat))
```

## Homoscedastic Standard Deviations

First, we simulate data using standard deviations that do not depend on any predictor variables, i.e. are homoscedastic.
We do not simulate any fixed effects structure, in this example we focus on biases in the estimation of standard deviations.

First, we fix the standard deviations:
``` {r sim1-fix-sd}
tau_sim <- 0.4
phi_s2s_sim <- 0.43
phi_ss_sim <- 0.5
```

Next, we randomly sample event terms, site terms, and withn-event/within-site residuals, and combine them into total residuals (our target variable for this example).
``` {r sim1-sample}
set.seed(5618)
# randomly sample residals, event and site terms
dWS_sim <- rnorm(n_rec, sd = phi_ss_sim)
dS_sim <- rnorm(n_stat, sd = phi_s2s_sim)
dB_sim <- rnorm(n_eq, sd = tau_sim)

# combine into total residual/target variable
data_reg$y_sim <- dB_sim[eq] + dS_sim[stat] + dWS_sim
```

Now we perform the linear mixed effects regression using `lmer`.
We use maximum likelihood instead of restricted maximum likelihood in this case to show the equivalence of the calculations of standard deviations.
In the paper, we also use Stan to estimate the random effects and standard deviations, but we omit this here to save time and space.
As we have seen for the Italian data, we get very similar results sing `lmer` and Stan, ad this is also reflected by the results shown in the paper.
Frequentist methods are still overwhelmingly used in GMM development, so it makes sense to focus on them here.

```{r sim1-lmer}
fit_sim <- lmer(y_sim ~ (1 | eq) + (1 | stat), data_reg, REML = FALSE)
summary(fit_sim)
```

As we can see, the model parameters are quite well estimated.
The intercept is close to zero, and the standard deviations are close to the values used in the simulation.

Below, we extract the conditional modes and standard deviations of the random effects.
We also calculate the within-event/within-site residuals, and approximate their standard deviation.

``` {r sim1-extract}
tmp <- as.data.frame(ranef(fit_sim))
dS_lmer <- tmp[tmp$grpvar == 'stat','condval']
dB_lmer <- tmp[tmp$grpvar == 'eq','condval']
dWS_lmer <- data_reg$y_sim - predict(fit_sim)

sd_dS_lmer <- tmp[tmp$grpvar == 'stat','condsd']
sd_dB_lmer <- tmp[tmp$grpvar == 'eq','condsd']
sd_dWS_lmer <- sqrt(sd_dB_lmer[eq]^2 + sd_dS_lmer[stat]^2) # approximately

# alternative way to extract the random effects and conditional standard deviations
# dS_lmer <- ranef(fit_sim)$stat$`(Intercept)`
# dB_lmer <- ranef(fit_sim)$eq$`(Intercept)`
# 
# sd_dB_lmer <- as.numeric(arm::se.ranef(fit_sim)$eq)
# sd_dS_lmer <- as.numeric(arm::se.ranef(fit_sim)$stat)
```

Next, we compare different standard deviations.
For all terms, we show the true value used in the simulations, the standard devation of the sampled terms, and then the value from the fit using `lmer`.
Then, we calculate the standard deviations according to Equation (4) in the paper (including uncertainty).
We also show the standard deviations calculated based on the conditional modes of the random effects/residuals, as well as calculated using a sample from the conditional distribution.

``` {r sim1-calc-sd}
# compare estiamtes of standard deviations
df <- data.frame(phi_s2s = c(phi_s2s_sim,
                       sd(dS_sim),
                       as.data.frame(VarCorr(fit_sim))$sdcor[1], 
                       sqrt(sum(dS_lmer^2)/n_stat + sum(sd_dS_lmer^2)/n_stat),
                       sd(dS_lmer),
                       sd(rnorm(n_stat, mean = dS_lmer, sd = sd_dS_lmer))),
           tau = c(tau_sim, 
                   sd(dB_sim),
                   as.data.frame(VarCorr(fit_sim))$sdcor[2], 
                   sqrt(sum(dB_lmer^2)/n_eq + sum(sd_dB_lmer^2)/n_eq),
                   sd(dB_lmer),
                   sd(rnorm(n_eq, mean = dB_lmer, sd = sd_dB_lmer))),
           phi_ss = c(phi_ss_sim,
                      sd(dWS_sim),
                      as.data.frame(VarCorr(fit_sim))$sdcor[3], 
                      sqrt(sum(dWS_lmer^2)/n_rec + sum(sd_dWS_lmer^2)/n_rec), 
                      sd(dWS_lmer),
                      sd(rnorm(n_rec, mean = dWS_lmer, sd = sd_dWS_lmer))),
           row.names = c('sim','sd(true)', 'lmer', 'with unc','sd(point estimate)','sd(sample)')
)
knitr::kable(df, digits = 5, row.names = TRUE,
             caption = "Comparison of standard deviation estimates.")

```

As we can see, the values from `lmer` and calculated according to Equation (4) agree for $\tau$ and $\phi_{S2S}$.
For $\phi_{SS}$, there is a small discrepancy, since the conditional standard deviations are just an approximation.
These values are also close to the true ones, while the standard deviations calculated from the point estimates are underestimating the true values.
The differences is largest for $\phi_{S2S}$, since there are several stations with only few recordings and thus large conditional standard deviations.
Sampling from the conditional distrbution of the random effects/standard deviations leads to values that are closer to the true ones.

Since there are many stations with very few recordings, the value of $\phi_{S2S}$ is severely underestimated when calculated from the point estimates of the site terms.
Thus, we now test whether what happens if we only use stations with at least 5 or 10 recordings.
As we can see from the histogram (which shows 200 repeated simulations), on average the values are closer to the true value, but some bias remains.
If one chooses to go this route, one also has to account for the fact that the estimates are based on fewer stations.

``` {r sim1-phis2s, cache=TRUE}
n_sam <- 200
res_s2s <- matrix(nrow = n_sam, ncol = 4)
set.seed(5618)
for(i in 1:n_sam) {
  rect <- rnorm(n_rec, sd = phi_ss_sim)
  statt <- rnorm(n_stat, sd = phi_s2s_sim)
  eqtt <- rnorm(n_eq, sd = tau_sim)
  
  data_reg$y_sim <- eqtt[eq] + statt[stat] + rect
  
  fit_sim <- lmer(y_sim ~ (1 | eq) + (1 | stat), data_reg)
  tmp <- ranef(fit_sim)$stat$`(Intercept)`
  res_s2s[i,] <- c(as.data.frame(VarCorr(fit_sim))$sdcor[1],
                   sd(tmp), sd(tmp[table(stat) >= 5]), sd(tmp[table(stat) >= 10]))
}

data.frame(res_s2s) |> set_names(c('lmer', 'all','N_rec >= 5','N_rec >= 10')) |>
  pivot_longer(everything()) |>
  ggplot() +
  geom_density(aes(x = value, color = name),linewidth = 1.5, key_glyph = draw_key_path) +
  geom_vline(xintercept = phi_s2s_sim, linewidth = 1.5) +
  guides(color = guide_legend(title = NULL)) +
  xlab('phi_S2S') +
  theme(legend.position = c(0.4,0.8))
```


In GMM development, the standard deviations are often modeled as dependent on some predictor variables such as magnitude.
@Bayless2018 contains a magnitude-dependent $\phi_{S2S}$, which is modeled using the mean magnitude of all records by station.
@Kotha2022 performed a Breusch-Pagan test [@Breusch1979] for heteroscedasticity to test for magnitude dependence of $\tau$ and $\phi_{SS}$.
Below, we calcuale the p-values for the simulated data (which we know is not heteroscedastic).
The null hypothesis is that the data is homoscedastc, and a low p-value is the probability of observing data if the null hypothesis were true.
Based on point estimates, one would conclude that site terms and within-event/within-site residuals are heteroscedastic.
In this context, be aware of hypothesis tests [@Wasserstein2019],[@Amrhein2019].

```{r sim1-bptest}
# calculate p-value of Breusch-Pagan test, testing for dependence on magnitude
df <- data.frame(
  dS = c(lmtest::bptest(dS ~ M, data = data.frame(M = magstat, dS = dS_lmer))$p.value,
         lmtest::bptest(dS ~ M, data = data.frame(M = magstat, dS = rnorm(n_stat, mean = dS_lmer, sd = sd_dS_lmer)))$p.value,
         lmtest::bptest(dS ~ M, data = data.frame(M = magstat, dS = dS_sim))$p.value),
  
  dB = c(lmtest::bptest(dB ~ M, data = data.frame(M = mageq, dB = dB_lmer))$p.value,
         lmtest::bptest(dB ~ M, data = data.frame(M = mageq, dB = rnorm(n_eq, mean = dB_lmer, sd = sd_dB_lmer)))$p.value,
         lmtest::bptest(dB ~ M, data = data.frame(M = mageq, dB = dB_sim))$p.value),
  
  dWS = c(lmtest::bptest(dWS ~ M, data = data.frame(M = data_reg$M, dWS = dWS_lmer))$p.value,
          lmtest::bptest(dWS ~ M, data = data.frame(M = data_reg$M, dWS = rnorm(n_rec, mean = dWS_lmer, sd = sd_dWS_lmer)))$p.value,
          lmtest::bptest(dWS ~ M, data = data.frame(M = data_reg$M, dWS = dWS_sim))$p.value),
  row.names = c('point estimate','sample','true'))

knitr::kable(df, digits = 5, row.names = TRUE,
             caption = "P-values from Breusch-Pagan test.")
```

Below, we calculate the standard deviations of the site terms $\delta S$, the event terms $\delta B$, and the residuals $\delta WS$, both for the simulated (true) values, and the point estimates from the `lmer` fit.
The true value of the standard deviation is shown as a horizontal black line.

We can decreasing values wth magnitude in the standard deviations estimated from the point estimates for $\phi_{S2S}$ and $\phi_{SS}$, while the values calculated from the true samples are more constant (as they shold be).
While one always needs to be careful with different numbers of events/records/stations within each bin, plots like these (wth patterns as in these plots) are often used to conclude that standard deviations ($\phi_{S2S}$ and $\phi_{SS}$ in this case) should be modeled as magnitude dependent, which in this case is not true.

``` {r sim1-plot-sd-bin, out.width = '100%', fig.width=12}
# mamgnitude break points for bins
magbins <- c(3,4,5,6,7,8)

# site terms
df_stat <- data.frame(M = magstat, dS_sim, dS_lmer) %>% 
  mutate(bin = cut(M, breaks = magbins, labels = FALSE)) %>%
  group_by(bin) %>%
  mutate(sd_sim = sd(dS_sim),
         sd_lmer = sd(dS_lmer),
         meanM = mean(M)) %>%
  arrange(M)

p1 <- cbind(unique(df_stat[,c('sd_sim','sd_lmer','meanM')]), 
      m1 = magbins[1:(length(magbins)-1)],
      m2 = magbins[2:length(magbins)]) |>
  pivot_longer(!c(m1,m2,meanM)) |>
  ggplot() +
  geom_segment(aes(x = m1, xend = m2, y=value, yend = value, color = name), linewidth = 1.5) +
  scale_color_manual(values = c('red','blue'),
                     labels = c('lmer','sim')) +
  geom_hline(yintercept = phi_s2s_sim, linewidth = 1.5) +
  guides(color = guide_legend(title=NULL)) +
  labs(x = 'M', y = 'phi_S2S') +
  theme(legend.position = c(0.2,0.2))

# event terms
df_eq <- data.frame(M = mageq, dB_sim, dB_lmer) %>% 
  mutate(bin = cut(M, breaks = magbins, labels = FALSE)) %>%
  group_by(bin) %>%
  mutate(sd_sim = sd(dB_sim),
         sd_lmer = sd(dB_lmer),
         meanM = mean(M)) %>%
  arrange(M)

p2 <- cbind(unique(df_eq[,c('sd_sim','sd_lmer','meanM')]), 
      m1 = magbins[1:(length(magbins)-1)],
      m2 = magbins[2:length(magbins)]) |>
  pivot_longer(!c(m1,m2,meanM)) |>
  ggplot() +
  geom_segment(aes(x = m1, xend = m2, y=value, yend = value, color = name), linewidth = 1.5) +
  scale_color_manual(values = c('red','blue'),
                     labels = c('lmer','sim')) +
  geom_hline(yintercept = tau_sim, linewidth = 1.5) +
  guides(color = guide_legend(title=NULL)) +
  labs(x = 'M', y = 'tau') +
  theme(legend.position = 'none')

# residuals
df_rec <- data.frame(M = data_reg$M, dWS_sim, dWS_lmer) %>% 
  mutate(bin = cut(M, breaks = magbins, labels = FALSE)) %>%
  group_by(bin) %>%
  mutate(sd_sim = sd(dWS_sim),
         sd_lmer = sd(dWS_lmer),
         meanM = mean(M)) %>%
  arrange(M)

p3 <- cbind(unique(df_rec[,c('sd_sim','sd_lmer','meanM')]), 
      m1 = magbins[1:(length(magbins)-1)],
      m2 = magbins[2:length(magbins)]) |>
  pivot_longer(!c(m1,m2,meanM)) |>
  ggplot() +
  geom_segment(aes(x = m1, xend = m2, y=value, yend = value, color = name), linewidth = 1.5) +
  scale_color_manual(values = c('red','blue'),
                     labels = c('lmer','sim')) +
  geom_hline(yintercept = phi_ss_sim, linewidth = 1.5) +
  guides(color = guide_legend(title=NULL)) +
  labs(x = 'M', y = 'phi_SS') +
  theme(legend.position = 'none')

patchwork::wrap_plots(p1,p2,p3, ncol = 2)
```

## Magnitude-Dependent Tau and Phi_SS

In this section, we estimate magnitude dependent standard deviations.
We simulate data with magnitude dependent $\tau$ and $\phi_{SS}$.
The dependence has the form
$$
\tau(M) = \left\{
  \begin{array}{ll}
    {\tau}_1 & M \leq M_1 \\
    {\tau}_1 + ({\tau}_2 - {\tau}_1) \frac{M - M_1}{M_2 - M_1} & M_1 < M < M_2 \\
    {\tau}_2 & M \geq M_2
  \end{array}
  \right.
$$
with a form similar for $\phi_{SS}$.

For this simulation, we also generate median predictions from fixed effects, in order to check how well the coefficients are estimated.

First, we declare the values of the standard deviations for the simulations.
``` {r sim2-hs-sd}
# fix standard deviations and magnitude break points
phi_s2s_sim <- 0.43
tau_sim_val <- c(0.4,0.25)
phi_ss_sim_val <- c(0.55,0.4)
mb_tau <- c(5,6)
mb_phi <- c(4.5,5.5)

# define tau for each event
# define linear predictors
m1_eq <- 1 * (mageq < mb_tau[2]) - (mageq - mb_tau[1]) / (mb_tau[2] - mb_tau[1]) * (mageq > mb_tau[1] & mageq < mb_tau[2])
m2_eq <- 1 * (mageq >= mb_tau[2]) + (mageq - mb_tau[1]) / (mb_tau[2] - mb_tau[1]) * (mageq > mb_tau[1] & mageq < mb_tau[2])

tau_sim <- m1_eq * tau_sim_val[1] + m2_eq * tau_sim_val[2]

# define phi_ss for each record
# define linear predictors
m1_rec <- 1 * (data_reg$M < mb_phi[2]) - (data_reg$M - mb_phi[1]) / (mb_phi[2] - mb_phi[1]) * (data_reg$M > mb_phi[1] & data_reg$M < mb_phi[2])
m2_rec <- 1 * (data_reg$M >= mb_phi[2]) + (data_reg$M - mb_phi[1]) / (mb_phi[2] - mb_phi[1]) * (data_reg$M > mb_phi[1] & data_reg$M < mb_phi[2])

phi_ss_sim <- m1_rec * phi_ss_sim_val[1] + m2_rec * phi_ss_sim_val[2]
```

Now, we declare the coefficients, which are taken from the ITA18 model of @Lanzano2019.
We also compute the linear predictors for the model.

``` {r sim2-hs-coeff}
coeffs <- c(3.421046409, 0.193954090, -0.021982777, 0.287149291, -1.405635476, -0.002911264, -0.394575970)
names_coeffs <- c("intercept", "M1", "M2", "MlogR", "logR", "R", "logVS")

# Set linear predictors
mh = 5.5
mref = 5.324
h = 6.924
data_reg$M1 <- (data_reg$M-mh)*(data_reg$M<=mh)
data_reg$M2 <- (data_reg$M-mh)*(data_reg$M>mh)
data_reg$MlogR <- (data_reg$M-mref)*log10(sqrt(data_reg$Rjb^2+h^2))
data_reg$logR <- log10(sqrt(data_reg$Rjb^2+h^2))
data_reg$R <- sqrt(data_reg$Rjb^2+h^2)
data_reg$logVS <- log10(data_reg$VS_gmean/800)*(data_reg$VS_gmean<=1500)+log10(1500/800)*(data_reg$VS_gmean>1500)
```

Now, we randomly sample event terms, site terms, and residuals, and combine with median predictions.

``` {r sim2-hs-calc-y}
set.seed(1701)
dB_sim <- rnorm(n_eq, sd = tau_sim)
dWS_sim <- rnorm(n_rec, sd = phi_ss_sim)
dS_sim <- rnorm(n_stat, sd = phi_s2s_sim)

data_reg$y_sim <- as.matrix(data_reg[,names_coeffs]) %*% coeffs + dB_sim[eq] + dS_sim[stat] + dWS_sim
```

Firs, we perform a linear mixed effects regression (which assumes homoscedastic standard deviations).
In general, the coefficients are estimated well, but the standard deviations are off.

``` {r sim2-hs-lmer}
# linear mixed effects regression
fit_sim <- lmer(y_sim ~ M1 + M2 + MlogR + logR + R + logVS + (1 | eq) + (1 | stat), data_reg)
summary(fit_sim)

# extract conditional modes and standard deviations of residuals/random effects
tmp <- as.data.frame(ranef(fit_sim))
dS_lmer <- tmp[tmp$grpvar == 'stat','condval']
dB_lmer <- tmp[tmp$grpvar == 'eq','condval']
dWS_lmer <- data_reg$y_sim - predict(fit_sim)

sd_dS_lmer <- tmp[tmp$grpvar == 'stat','condsd']
sd_dB_lmer <- tmp[tmp$grpvar == 'eq','condsd']
sd_dWS_lmer <- sqrt(sd_dB_lmer[eq]^2 + sd_dS_lmer[stat]^2) # approximately

# calculate total resduals
dR_lmer <- data_reg$y_sim - predict(fit_sim, re.form=NA)
```

Next, we run a Stan model [@Carpenter2016], <https://mc-stan.org/>, on the total residuals.
In the Stan model, we can mdel the standard deviations to be magnitude dependent.
Below, we compile the Stan model, and print out its code.

``` {r sim2-hs-stan-part}
mod <- cmdstan_model(file.path('./Git/MixedModels_Biases/', 'stan', 'gmm_partition_tauM_phiM.stan'))
mod
```

Now, we declare the data for Stan, and run the model.
To keep running time low, we only run 200 warm-up and 200 sampling iterations.

``` {r sim2-hs-stan-part-run, cache = TRUE}
data_list <- list(
  N = n_rec,
  NEQ = n_eq,
  NSTAT = n_stat,
  Y = as.numeric(dR_lmer),
  eq = eq,
  stat = stat,
  MEQ = mageq,
  M1_eq = m1_eq,
  M2_eq = m2_eq,
  M1_rec = m1_rec,
  M2_rec = m2_rec
)

fit <- mod$sample(
  data = data_list,
  seed = 8472,
  chains = 4,
  iter_sampling = 200,
  iter_warmup = 200,
  refresh = 100,
  max_treedepth = 10,
  adapt_delta = 0.8,
  parallel_chains = 2,
  show_exceptions = FALSE
)
print(fit$cmdstan_diagnose())
print(fit$diagnostic_summary())
draws_part <- fit$draws()

summarise_draws(subset(draws_part, variable = c('ic','phi','tau'), regex = TRUE))
```
In general, the parameters are well estimated.
There are not that many events for $M \geq 6$, so the value of $\tau_2$ is quite uncertain.

In the following, we run a Stan model which estimates coefficients and magitude-dependent standard deviations at the same time.
To improve sampling, we use the QR-decomposition of the desgn matrix.

``` {r sim2-hs-stan-full, cache = TRUE}
mod <- cmdstan_model(file.path('./Git/MixedModels_Biases/', 'stan', 'gmm_full_qr_tauM_phiM.stan'))
mod

data_list <- list(
  N = n_rec,
  NEQ = n_eq,
  NSTAT = n_stat,
  K = length(coeffs),
  Y = as.numeric(data_reg$y_sim),
  X = data_reg[,c("M1", "M2", "MlogR", "logR", "R", "logVS")], # design matrix
  eq = eq,
  stat = stat,
  MEQ = mageq,
  M1_eq = m1_eq,
  M2_eq = m2_eq,
  M1_rec = m1_rec,
  M2_rec = m2_rec
)

fit <- mod$sample(
  data = data_list,
  seed = 8472,
  chains = 4,
  iter_sampling = 200,
  iter_warmup = 200,
  refresh = 100,
  max_treedepth = 10,
  adapt_delta = 0.8,
  parallel_chains = 2,
  show_exceptions = FALSE
)
print(fit$cmdstan_diagnose())
print(fit$diagnostic_summary())
draws_full <- fit$draws()

summarise_draws(subset(draws_full, variable = c('phi','tau'), regex = TRUE))
summarise_draws(subset(draws_full, variable = c('^c\\['), regex = TRUE))
```

The standard deviations are well estimated (very similar to the values based on partitioning the total residuals from the `lmer` fit), and the coefficients are also well estimated.


Below, we plot the posterior distribution of $\tau_1$ and $\tau_2$, together with the true value (black) and the value estimated from point estimates of the event terms in the respective magnitude bins (red), with (solid) and without (dashed) uncertainty.

``` {r sim2-hs-plot-tau, out.width = '100%', fig.width=16}
tmp <- mageq <= mb_tau[1]
tmp <- sqrt((sum(dB_lmer[tmp]^2) + sum(sd_dB_lmer[tmp]^2)) / sum(tmp))

p1 <- data.frame(dR = subset(as_draws_matrix(draws_part), variable = 'tau_1', regex = FALSE),
           full = subset(as_draws_matrix(draws_full), variable = 'tau_1', regex = FALSE)) |>
  set_names(c('dR','full')) |>
  pivot_longer(everything()) |>
  ggplot() +
  geom_density(aes(x = value, color = name), linewidth = 1.5, key_glyph = draw_key_path) +
  geom_vline(xintercept = tau_sim_val[1], linewidth = 1.5) +
  geom_vline(xintercept = sd(dB_lmer[mageq <= mb_tau[1]]), linewidth = 1.5, color = 'red') +
  geom_vline(xintercept = tmp, , linewidth = 1.5, color = 'red', linetype = 'dashed') +
  guides(color = guide_legend(title = NULL)) +
  theme(legend.position = c(0.8,0.8)) +
  xlab('tau_1')


tmp <- mageq >= mb_tau[2]
tmp <- sqrt((sum(dB_lmer[tmp]^2) + sum(sd_dB_lmer[tmp]^2)) / sum(tmp))

p2 <- data.frame(dR = subset(as_draws_matrix(draws_part), variable = 'tau_2', regex = FALSE),
           full = subset(as_draws_matrix(draws_full), variable = 'tau_2', regex = FALSE)) |>
  set_names(c('dR','full')) |>
  pivot_longer(everything()) |>
  ggplot() +
  geom_density(aes(x = value, color = name), linewidth = 1.5, key_glyph = draw_key_path) +
  geom_vline(xintercept = tau_sim_val[2], linewidth = 1.5) +
  geom_vline(xintercept = sd(dB_lmer[mageq >= mb_tau[2]]), linewidth = 1.5, color = 'red') +
  geom_vline(xintercept = tmp, , linewidth = 1.5, color = 'red', linetype = 'dashed') +
  guides(color = guide_legend(title = NULL)) +
  theme(legend.position = c(0.8,0.8)) +
  xlab('tau_2')

patchwork::wrap_plots(p1,p2)
```

While we see here that the values of $\tau_1$ and $\tau_2$ are estimated ok from `lmer`, in the paper we show results from 100 simulations which reveal on average a strong bias, whereas estimates from the Stan models are on average better.

Below, we show posterior distributions of $\phi_{SS,1}$ and $\phi_{SS,2}$, similar to the plots for $\tau_1$ and $\tau_2$.
In this case, we see strong biases for the estimates from `lmer`.

``` {r sim2-hs-plot-phiss, out.width = '100%', fig.width=16}
tmp <- data_reg$M <= mb_phi[1]
tmp <- sqrt((sum(dWS_lmer[tmp]^2) + sum(sd_dWS_lmer[tmp]^2)) / sum(tmp))

p1 <- data.frame(dR = subset(as_draws_matrix(draws_part), variable = 'phi_ss_1', regex = FALSE),
           full = subset(as_draws_matrix(draws_full), variable = 'phi_ss_1', regex = FALSE)) |>
  set_names(c('dR','full')) |>
  pivot_longer(everything()) |>
  ggplot() +
  geom_density(aes(x = value, color = name), linewidth = 1.5, key_glyph = draw_key_path) +
  geom_vline(xintercept = phi_ss_sim_val[1], linewidth = 1.5) +
  geom_vline(xintercept = sd(dWS_lmer[data_reg$M <= mb_phi[1]]), linewidth = 1.5, color = 'red') +
  geom_vline(xintercept = tmp, linewidth = 1.5, color = 'red', linetype = 'dashed') +
  guides(color = guide_legend(title = NULL)) +
  theme(legend.position = c(0.8,0.8)) +
  xlab('phi_ss_1')


tmp <- data_reg$M >= mb_phi[2]
tmp <- sqrt((sum(dWS_lmer[tmp]^2) + sum(sd_dWS_lmer[tmp]^2)) / sum(tmp))

p2 <- data.frame(dR = subset(as_draws_matrix(draws_part), variable = 'phi_ss_2', regex = FALSE),
           full = subset(as_draws_matrix(draws_full), variable = 'phi_ss_2', regex = FALSE)) |>
  set_names(c('dR','full')) |>
  pivot_longer(everything()) |>
  ggplot() +
  geom_density(aes(x = value, color = name), linewidth = 1.5, key_glyph = draw_key_path) +
  geom_vline(xintercept = phi_ss_sim_val[2], linewidth = 1.5) +
  geom_vline(xintercept = sd(dWS_lmer[data_reg$M >= mb_phi[2]]), linewidth = 1.5, color = 'red') +
  geom_vline(xintercept = tmp, linewidth = 1.5, color = 'red', linetype = 'dashed') +
  guides(color = guide_legend(title = NULL)) +
  theme(legend.position = c(0.8,0.8)) +
  xlab('phi_ss_2')

patchwork::wrap_plots(p1,p2)
```

And finally, the posterior distribution of $\phi_{S2S}$.

``` {r sim2-hs-plot-phis2s}
data.frame(dR = subset(as_draws_matrix(draws_part), variable = 'phi_s2s', regex = FALSE),
                 full = subset(as_draws_matrix(draws_full), variable = 'phi_s2s', regex = FALSE)) |>
  set_names(c('dR','full')) |>
  pivot_longer(everything()) |>
  ggplot() +
  geom_density(aes(x = value, color = name), linewidth = 1.5, key_glyph = draw_key_path) +
  geom_vline(xintercept = phi_s2s_sim, linewidth = 1.5) +
  geom_vline(xintercept = sd(dS_lmer), linewidth = 1.5, color = 'red') +
  geom_vline(xintercept = sqrt((sum(dS_lmer^2) + sum(sd_dS_lmer^2)) / n_stat),
             linewidth = 1.5, color = 'red', linetype = 'dashed') +
  guides(color = guide_legend(title = NULL)) +
  theme(legend.position = c(0.3,0.8)) +
  xlab('phi_S2S')
```

We can conclude from this smulation (and the repeated ones in the paper) that the magnitude-dependent standard deviations can be estimated using Stan from total residuals, but one should also account for uncertainty.
Estimating the values from binned random effects/residuals can work but leads to a larger bias.

Our focus is on estimating the magnitude-dependent standard deviations, but as a check we also plot the posterior distrbutions of the coefficients for the full stan model, together with the true values (black) and `lmer` estimates (red).

```{r sim2-hs-coeffs, out.width = '100%', fig.width=16}
df <- data.frame(Parameter = c('c[1]','c[2]','c[3]','c[4]','c[5]','c[6]','c[7]'),
           true = coeffs, lmer = fixef(fit_sim))

mcmc_hist(draws_full,regex_pars = 'c\\[') +
  geom_vline(aes(xintercept = true), data = df, linewidth = 1.5) +
  geom_vline(aes(xintercept = lmer), data = df, linewidth = 1.5, color = 'red')
```

### Estimating Break Points

In the previous section, we have simulated data with magnitude-dependent $\tau$ and $\phi$, using a trilnear function for the magnitude dependence.
In the Stan code, we have used the same fuctional form, and assumed that the magnitude break points are known.
Here, we relax this assumption.
We cannot directly estimate the break points since the Hamiltonian Monte Carlo algorithm of Stan relies on differentiation the model with respect to the parameters (loosely speaking), which leads to problems for functions with sharp beaks.
Instead, we model the dependence using the ``logistic sigmoid'' function (called `inv_logit` in Stan), which is defined as
$$
\sigma(x) = \frac{1}{1 + \exp(-x)}
$$
Below, we run a Stan model where both $\phi_{SS}$ and $\tau$ are modeled using this function.
``` {r sim2-hs-stan-logsig, cache=TRUE}
mod <- cmdstan_model(file.path('./Git/MixedModels_Biases/', 'stan', 'gmm_partition_tauM_phiM_invlogit.stan'))
mod

data_list <- list(
  N = n_rec,
  NEQ = n_eq,
  NSTAT = n_stat,
  Y = as.numeric(dR_lmer),
  eq = eq,
  stat = stat,
  MEQ = mageq
)

fit <- mod$sample(
  data = data_list,
  seed = 8472,
  chains = 4,
  iter_sampling = 200,
  iter_warmup = 200,
  refresh = 100,
  max_treedepth = 10,
  adapt_delta = 0.8, # increase to avoid divergences
  parallel_chains = 2,
  show_exceptions = FALSE
)
print(fit$cmdstan_diagnose())
print(fit$diagnostic_summary())
draws_part2 <- fit$draws()

summarise_draws(subset(draws_part2, variable = c('ic','phi','tau'), regex = TRUE))
```
We get some warnings about incomplete mixing, which we will ignore here.
We ranonly 400 iterations in total, and some longer chains probably lead to R-hat values that are closer to 1.


We now plot the magnitude dependence of $\tau$ and $\phi_{SS}$, estimated using the correct functional form and the logistic sigmoid function.
For $\tau$, the end values are similiar, but the transition is not well estimated with the logistic sigmoid function.
Ths s due to the fact that there are not many events in total (and not many at large magnitudes), which makes the estimation difficult.
For $\phi_{SS}$, on the other hand, the two estimated functions agree quite well.

``` {r sim2-hs-logsig-results, out.width = '100%', fig.width=16}
# function to calculate lnear predictos for magnitude scaling with break points
func_sd_mag <- function(mag, mb) {
  m1 <- 1 * (mag < mb[2]) - (mag - mb[1]) / (mb[2] - mb[1]) * (mag > mb[1] & mag < mb[2])
  m2 <- 1 * (mag >= mb[2]) + (mag - mb[1]) / (mb[2] - mb[1]) * (mag > mb[1] & mag < mb[2])
  
  return(list(m1 = m1, m2 = m2))
  
}

# logistic sigmoid function
logsig <- function(x) {1/(1 + exp(-x))}

# magnitudes for plotting
mags_f <- seq(3,8,by=0.1)
mags <- func_sd_mag(mags_f, mb_tau)
tau_m <- as_draws_matrix(subset(draws_part, variable = 'tau_1')) %*% matrix(mags$m1, nrow = 1) +
  as_draws_matrix(subset(draws_part, variable = 'tau_2')) %*% matrix(mags$m2, nrow = 1)

# posterior distribution of tau values for different magnitudes
tau_m_sig <- sapply(mags_f,
                    function(m) {as_draws_matrix(subset(draws_part2, variable = 'tau_1')) - 
                        as_draws_matrix(subset(draws_part2, variable = 'tau_2')) *
                        logsig((m - as_draws_matrix(subset(draws_part2, variable = 'mb_tau'))) *
                                 as_draws_matrix(subset(draws_part2, variable = 'tau_scale')))})


p1 <- data.frame(M = mags_f, 
           mean_true = tau_sim_val[1] * mags$m1 + tau_sim_val[2] * mags$m2,
           mean_mod1 = colMeans(tau_m),
           q05_mod1 = colQuantiles(tau_m, probs = 0.05),
           q95_mod1 = colQuantiles(tau_m, probs = 0.95),
           mean_mod2 = colMeans(tau_m_sig),
           q05_mod2 = colQuantiles(tau_m_sig, probs = 0.05),
           q95_mod2 = colQuantiles(tau_m_sig, probs = 0.95)) |>
  pivot_longer(!M, names_sep = '_', names_to = c('par','mod')) |>
  ggplot() +
  geom_line(aes(x = M, y=value, color = mod, linetype = par), linewidth = 1.5) +
  guides(color = guide_legend(title = NULL), linetype = guide_legend(title = NULL)) +
  theme(legend.position = c(0.2,0.3)) +
  scale_color_manual(values = c('red','blue','black'),
                     labels = c('tri-linear','logistic sigmoid','true')) +
  labs(x = 'M', y = 'tau')

############ phi
mags <- func_sd_mag(mags_f, mb_phi)
phi_m <- as_draws_matrix(subset(draws_part, variable = 'phi_ss_1')) %*% matrix(mags$m1, nrow = 1) +
  as_draws_matrix(subset(draws_part, variable = 'phi_ss_2')) %*% matrix(mags$m2, nrow = 1)

# posterior distribution of tau values for different magnitudes
phi_m_sig <- sapply(mags_f,
                    function(m) {as_draws_matrix(subset(draws_part2, variable = 'phi_ss_1')) - 
                        as_draws_matrix(subset(draws_part2, variable = 'phi_ss_2')) *
                        logsig((m - as_draws_matrix(subset(draws_part2, variable = 'mb_phi_ss'))) *
                                 as_draws_matrix(subset(draws_part2, variable = 'phi_ss_scale')))})


p2 <- data.frame(M = mags_f, 
           mean_true = phi_ss_sim_val[1] * mags$m1 + phi_ss_sim_val[2] * mags$m2,
           mean_mod1 = colMeans(phi_m),
           q05_mod1 = colQuantiles(phi_m, probs = 0.05),
           q95_mod1 = colQuantiles(phi_m, probs = 0.95),
           mean_mod2 = colMeans(phi_m_sig),
           q05_mod2 = colQuantiles(phi_m_sig, probs = 0.05),
           q95_mod2 = colQuantiles(phi_m_sig, probs = 0.95)) |>
  pivot_longer(!M, names_sep = '_', names_to = c('par','mod')) |>
  ggplot() +
  geom_line(aes(x = M, y=value, color = mod, linetype = par), linewidth = 1.5) +
  guides(color = guide_legend(title = NULL), linetype = guide_legend(title = NULL)) +
  theme(legend.position = c(0.2,0.3)) +
  scale_color_manual(values = c('red','blue','black'),
                     labels = c('tri-linear','logistic sigmoid','true')) +
  labs(x = 'M', y = 'phi_SS')

patchwork::wrap_plots(p1, p2)
```

## Estimating Scaling from Point Estimates of Random Effects

Random effects are sometimes used to estimate scaling of ground motions wth respect to new parameters, such as parameters associated with horizontal-to-vertical ratios.
To assess potential biases, we simulate synthetic data using the ITA18 functional form, and then estimate a model without $V_{S30}$-scaling.
We then estimate the $V_{S30}$-scaling coefficient from site terms.

The coefficients and linear predictors are already set.
Here, we use standard deviations in $log_{10}$-units, which is what was used in @Lanzano2019.
We generate some data, and fit a full model (including $V_{S30}$-scaling).

``` {r sim3-vs-1}
tau_sim <- 0.17
phi_s2s_sim <- 0.23
phi_sim <- 0.2

set.seed(1701)
dB_sim <- rnorm(n_eq, mean =0, sd = tau_sim)
dS_sim <- rnorm(n_stat, mean =0, sd = phi_s2s_sim)
dWS_sim <- rnorm(n_rec, mean = 0, sd = phi_sim)

data_reg$y_sim <- as.matrix(data_reg[,names_coeffs]) %*% coeffs + dB_sim[eq] + dS_sim[stat] + dWS_sim
fit_sim <- lmer(y_sim ~ M1 + M2 + MlogR + logR + R + logVS + (1|eq) + (1|stat), data_reg)
summary(fit_sim)
```

Now, we fit the model with the `logVS` term, and then use linear regression on the estimated station term to estiamte the coefficient.
To account for stations with few recordings, we also use only estmated site terms from staions with at least 10 records.
We also fit linear mixed effects model on the total residuals.


``` {r sim3-vs-fit2}
fit_sim2 <- lmer(y_sim ~ M1 + M2 + MlogR + logR + R + (1|eq) +(1|stat), data_reg)

deltaS_lmer2 <- ranef(fit_sim2)$stat$`(Intercept)`
deltaB_lmer2 <- ranef(fit_sim2)$eq$`(Intercept)`
data_reg$deltaR_lmer2 <- data_reg$y_sim - predict(fit_sim2, re.form=NA)
tmp <- data.frame(unique(data_reg[,c('stat','logVS')]), deltaS_lmer2 = deltaS_lmer2)

### all station terms
fit_sim2a <- lm(deltaS_lmer2 ~ logVS, tmp)
# summary(fit_sim2a)

### subset station ters
idx <- as.numeric(which(table(stat) >= 10))
fit_sim3a <- lm(deltaS_lmer2 ~ logVS, tmp[idx,])
# summary(fit_sim3a)

### total residuals
fit_sim4 <- lmer(deltaR_lmer2 ~ logVS + (1|eq) + (1|stat), data_reg)

df <- data.frame(name = c('true','full','dS(all)','dS(N>=10)','dR'),
           value = c(coeffs[7], fixef(fit_sim)[7], fit_sim2a$coefficients[2],
                     fit_sim3a$coefficients[2], fixef(fit_sim4)[2]))

knitr::kable(df, digits = 5, row.names = TRUE,
             caption = "Estimated VS30-scaling coefficient")
```

As we can see, the $V_{S30}$-scaling coefficient estimated from site terms $\delta S$ is strongly biased.
The bias persists even if only stations with 10 or more recordings are used.
A mixed-effects model on the total residuals works well to estimate the coefficient.

## Correlations between Random Effects

Here, we briefly show that estimating correlations between random effects/residuals can be well estimated from point estimates.
We simulate correlated terms from a bivariate normal distribution, perform a linear mixed-effects regression on each target variable separael, and then calcualte the correlation.
The correlation coefficient is
$$
\rho(X,Y) = \frac{cov(X,Y)}{\sigma_X \sigma_Y}
$$
We compare calculating $\rho$ using the standard deviations of the point estimates in the denominator, as well as the ML estimate from `lmer`.
The correlations are well estimated by using point estimates, but are underestimated when using the (RE)ML value in the denominator.


``` {r sim2-corr}
tau_sim <- 0.4
phi_s2s_sim <- 0.43
phi_ss_sim <- 0.5

rho <- 0.9
cov_tau <- matrix(c(tau_sim^2, rho * tau_sim * tau_sim,
                    rho * tau_sim * tau_sim, tau_sim^2), ncol = 2)
cov_s2s <- matrix(c(phi_s2s_sim^2, rho * phi_s2s_sim * phi_s2s_sim,
                    rho * phi_s2s_sim * phi_s2s_sim, phi_s2s_sim^2), ncol = 2)
cov_ss <- matrix(c(phi_ss_sim^2, rho * phi_ss_sim * phi_ss_sim,
                    rho * phi_ss_sim * phi_ss_sim, phi_ss_sim^2), ncol = 2)

eqt2 <- mvtnorm::rmvnorm(n_eq, sigma = cov_tau)
statt2 <- mvtnorm::rmvnorm(n_stat, sigma = cov_s2s)
rect2 <- mvtnorm::rmvnorm(n_rec, sigma = cov_ss)

data_reg$y_sim1 <- eqt2[eq,1] + statt2[stat,1] + rect2[,1]
data_reg$y_sim2 <- eqt2[eq,2] + statt2[stat,2] + rect2[,2]

fit_sim1 <- lmer(y_sim1 ~ (1 | eq) + (1 | stat), data_reg)
fit_sim2 <- lmer(y_sim2 ~ (1 | eq) + (1 | stat), data_reg)

dB1 <- ranef(fit_sim1)$eq$`(Intercept)`
dS1 <- ranef(fit_sim1)$stat$`(Intercept)`
dWS1 <-data_reg$y_sim1 - predict(fit_sim1)

dB2 <- ranef(fit_sim2)$eq$`(Intercept)`
dS2 <- ranef(fit_sim2)$stat$`(Intercept)`
dWS2 <-data_reg$y_sim2 - predict(fit_sim2)

sds1 <- as.data.frame(VarCorr(fit_sim1))$sdcor
sds2 <- as.data.frame(VarCorr(fit_sim2))$sdcor


df <- data.frame(dS = c(rho, cor(dS1,dS2), cov(dS1,dS2)/(sd(dS1) * sd(dS2)), cov(dS1,dS2)/(sds1[1] * sds2[1])),
           dB = c(rho, cor(dB1,dB2), cov(dB1,dB2)/(sd(dB1) * sd(dB2)), cov(dB1,dB2)/(sds1[2] * sds2[2])),
           dWS = c(rho, cor(dWS1,dWS2), cov(dWS1,dWS2)/(sd(dWS1) * sd(dWS2)), cov(dWS1,dWS2)/(sds1[3] * sds2[3])),
           row.names = c('true','cor','cov/sd(point estimate)','cov()/hat()'))
knitr::kable(df, digits = 3, row.names = TRUE,
             caption = "Estimated correlation coefficients.")
```

## Correlation with e.g. Stress Drop

```{r sim-corr-lmer}
tau_sim <- 0.4
phi_s2s_sim <- 0.43
phi_ss_sim <- 0.5

rho <- 0.7
tau2 <- 1

cov_tau <- matrix(c(tau_sim^2, rho * tau_sim * tau2, 
                    rho * tau_sim * tau2, tau2^2), ncol = 2)

set.seed(5618)
deltaWS_sim <- rnorm(n_rec, sd = phi_ss_sim)
deltaS_sim <- rnorm(n_stat, sd = phi_s2s_sim)
eqt2 <- mvtnorm::rmvnorm(n_eq, sigma = cov_tau)

y_sim <- eqt2[eq,1] + deltaS_sim[stat] + deltaWS_sim
data_reg$y_sim <- y_sim

fit_lmer_sim <- lmer(y_sim ~ (1 | eq) + (1 | stat), data_reg)
deltaB_lmer <- ranef(fit_lmer_sim)$eq$`(Intercept)`

cor(deltaB_lmer, eqt2[,2])
```

The fit by itself is ok, but in this case the correlation is underestimated.
For the paper, we have repeated this simulation 100 times, and on average we observe a bias.

In the following, we fit a Stan model to the data in which we directly estimate the correlation between the event terns and the other event related variable $E$during te model fitting phase, i.e. during partitioning.
This implicitly takes the uncertainty in the estimated event terms into account.
We model the two variables as a bivariate normal distribution, and use the conditional distribution of $\delta B$ given $E$ as the prior distribution for $\delta B$
$$
\begin{aligned}
  \delta B &\sim N(\mu_s, \tau_s) \\
  \mu_s &= \frac{\tau}{\sigma_{E}} \; \rho \;E \\
  \tau_s &= \sqrt{(1 - \rho^2) \tau^2}
\end{aligned}
$$

``` {r sim-corr-stan}
mod <- cmdstan_model(file.path('./Git/MixedModels_Biases/', 'stan', 'gmm_partition_wvar_corr.stan'))

data_list_cor <- list(
  N = n_rec,
  NEQ = n_eq,
  NSTAT = n_stat,
  Y = data_reg$y_sim,
  E = eqt2[,2],
  eq = eq,
  stat = stat,
  alpha = c(1,1,1)
)

fit <- mod$sample(
  data = data_list_cor,
  seed = 8472,
  chains = 4,
  iter_sampling = 200,
  iter_warmup = 200,
  refresh = 100,
  max_treedepth = 10,
  adapt_delta = 0.8,
  parallel_chains = 2,
  show_exceptions = FALSE
)
print(fit$cmdstan_diagnose())
print(fit$diagnostic_summary())
draws_corr <- fit$draws()


summarise_draws(subset(draws_corr, variable = c('rho', 'phi', 'tau'), regex = TRUE))
```

The fit looks good, and we also get a good estimate of $\rho$.

Below, we show the posterior distribution of the correlation coefficient $\rho$, together with the true value (black), the correlation between point estimates $\widehat{\delta B}$ and $E$ from `lmer` (red), and the correlation between the mean event terms (point estimates) from the Stan fit (blue).
The black dashed line is the mean of he posterior distribution of `rho`.

``` {r sm-corr-stan}
mcmc_hist(draws_corr, pars = 'rho') +
  vline_at(rho, linewidth = 1.5) +
  vline_at(colMeans(subset(as_draws_matrix(draws_corr), variable = 'rho', regex = FALSE)),
                    linewidth = 1.5, linetype = 'dashed') +
  vline_at(cor(deltaB_lmer, eqt2[,2]), linewidth = 1.5, color = 'red') +
  vline_at(cor(eqt2[,2], colMeans(subset(as_draws_matrix(draws_corr), variable = 'eqterm', regex = TRUE))),
           linewidth = 1.5, color = 'blue')
```

# Simulations using Italian Data

Now, we use the Italian data of @Lanzano2019 (see also @Caramenti2022) for simulations with spatial/nonergodic models.
This data was used in @Kuehn2022b for nonergodic model comparison, which made it easy to set up.

First, we read and prepare the data.

``` {r italy-data}
data_it <- read.csv(file.path('./Git/MixedModels_Biases/','/data','italian_data_pga_id_utm_stat.csv'))

# Set linear predictors
mh = 5.5
mref = 5.324
h = 6.924
attach(data_it)
b1 = (mag-mh)*(mag<=mh)
b2 = (mag-mh)*(mag>mh)
c1 = (mag-mref)*log10(sqrt(JB_complete^2+h^2))
c2 = log10(sqrt(JB_complete^2+h^2))
c3 = sqrt(JB_complete^2+h^2)
f1 = as.numeric(fm_type_code == "SS")
f2 = as.numeric(fm_type_code == "TF")
k = log10(vs30/800)*(vs30<=1500)+log10(1500/800)*(vs30>1500)
y = log10(rotD50_pga)
detach(data_it)

n_rec <- length(b1)
eq <- data_it$EQID
stat <- data_it$STATID
n_eq <- max(eq)
n_stat <- max(stat)
n_rec <- nrow(data_it)

mageq <- unique(data_it[,c('EQID','mag')])[,2]

data_reg <- data.frame(Y = y,
                       M1 = b1,
                       M2 = b2,
                       MlogR = c1,
                       logR = c2,
                       R = c3,
                       Fss = f1,
                       Frv = f2,
                       logVS = k,
                       eq = eq,
                       stat = stat,
                       intercept = 1,
                       M = data_it$mag
)

# coefficients from ITA18
coeffs <- c(3.421046409, 0.193954090, -0.021982777, 0.287149291,
            -1.405635476, -0.002911264, 0.085983743, 0.010500239,
            -0.394575970)
names_coeffs <- c("intercept", "M1", "M2", "MlogR", "logR", "R", "Fss", "Frv", "logVS")
```


``` {r italy-data-plots, out.width = '100%', fig.width=16}
p1 <- ggplot(data_it) +
  geom_point(aes(x = JB_complete, y = mag)) +
  scale_x_log10(breaks = breaks, minor_breaks = minor_breaks)
p2 <- ggplot(unique(data_it[,c('EQID','mag')])) +
  geom_histogram(aes(x = mag))
patchwork::wrap_plots(p1, p2)
```
We simulate data for some spatial models on the Italian data, and we use INLA (<https://www.r-inla.org/>) to estimate the models.
Below, we set the penalized complexity prior [@Simpson2017] for the standard deviations, used throughout.

``` {r italy-inla-priors}
prior_prec_tau <- list(prec = list(prior = 'pc.prec', param = c(0.3, 0.01)))
prior_prec_phiS2S    <- list(prec = list(prior = 'pc.prec', param = c(0.3, 0.01))) 
prior_prec_phiSS    <- list(prec = list(prior = 'pc.prec', param = c(0.3, 0.01)))
```

## Spatial correlations of Site Terms

In nonergodic models, site terms are often modeled as spatially correlated.
The spatial correlaion structure can be assessed from point estimates of the site terms.
Here, we simulate some data with spatially correlated site terms, to check whether we can get the model parameters back.

We use the Mat\'ern covariance function for the spatial correlation of the site terms, which is defined below.

``` {r cmatern}
cMatern <- function(h, nu, kappa) {
  ifelse(h > 0, besselK(h * kappa, nu) * (h * kappa)^nu / 
           (gamma(nu) * 2^(nu - 1)), 1)
}

# Function to sample from zero mean multivariate normal
rmvnorm0 <- function(n, cov, R = NULL) { 
  if (is.null(R))
    R <- chol(cov)
  
  return(crossprod(R, matrix(rnorm(n * ncol(R)), ncol(R))))
}
```

Next we define the coefficients, spatial range, and standard deviations for the simulation.

``` {r sim-it-spatial-def}
# unique station coordinates
co_stat_utm <- unique(data_it[,c("STATID", "X_stat","Y_stat")])[,c(2,3)]

range <- 30 # spatial range
nu <- 1
kappa <- sqrt(8*nu)/range

# standard deviations
wvar <- 0.65 # variance ratio for phi_s2s
tau_sim <- 0.17
phi_s2s_sim <- 0.23
phi_s2s_0 <- sqrt((1 - wvar) * phi_s2s_sim^2)
phi_s2s_c <- sqrt(wvar * phi_s2s_sim^2)
phi_ss_sim <- 0.2

cov <- phi_s2s_c^2 * cMatern(as.matrix(dist(co_stat_utm)), nu, kappa) + diag(10^-9, n_stat)
```

To se R-INLA with the ``stochastic partial differential equation'' (SPDE) approach, we need to define a mesh.
``` {r sim-it-spatial-mesh}
max.edge2    <- 5 
bound.outer2 <- 40 
mesh = inla.mesh.2d(loc=co_stat_utm,
                    max.edge = c(1,5)*max.edge2,
                    cutoff = max.edge2,
                    offset = c(5 * max.edge2, bound.outer2))
print(mesh$n)
```

Now we define priors for the standard deviations (based on @Simpson2017), the SPDE prior, the projecion matrix `A`, and the formula.

``` {r sim-it-spatial-spde}
spde_stat <- inla.spde2.pcmatern(
  # Mesh and smoothness parameter
  mesh = mesh, alpha = 2,
  # P(practic.range < 0.3) = 0.5
  prior.range = c(100, 0.9),
  # P(sigma > 1) = 0.01
  prior.sigma = c(.3, 0.01))

A_stat <- inla.spde.make.A(mesh, loc = as.matrix(co_stat_utm[stat,]))
A_stat_unique   <- inla.spde.make.A(mesh, loc = as.matrix(co_stat_utm))
idx_stat   <- inla.spde.make.index("idx_stat",spde_stat$n.spde)

# formula to be used on the total residuals
form_spatial_total <- y ~ 0 + intercept + 
  f(eq, model = "iid", hyper = prior_prec_tau) + 
  f(stat, model = "iid",hyper = prior_prec_phiS2S) +
  f(idx_stat, model = spde_stat)

# formula for the full fit
form_spatial_stat <- y ~ 0 + intercept + 
  M1 + M2 + MlogR + logR + R + Fss + Frv + logVS +
  f(eq, model = "iid", hyper = prior_prec_tau) + 
  f(stat, model = "iid",hyper = prior_prec_phiS2S) +
  f(idx_stat, model = spde_stat)

# formua for fit from site terms
form_spatial_stat_u <- y ~ 0 + intercept + f(idx_stat, model = spde_stat)
```


Now, we sample the event terms, site terms, spatially correlated site terms, and within-event/within-site residuals, and combine them with the median predictions from ITA18.
We then fit a `lmer` model to the data.

``` {r sim-it-spatial-sample}
set.seed(8472)
dB_sim <- rnorm(n_eq, mean =0, sd = tau_sim)
dS_sim <- rnorm(n_stat, mean =0, sd = phi_s2s_0)
dWS_sim <- rnorm(n_rec, mean = 0, sd = phi_ss_sim)

data_reg$y_sim <- as.matrix(data_reg[,names_coeffs]) %*% coeffs +
  dB_sim[eq] + dS_sim[stat] + dWS_sim + rmvnorm0(1, cov)[stat]

fit_sim <- lmer(y_sim ~ M1 + M2 + MlogR + logR + R + Fss + Frv + logVS + (1|eq) + (1|stat), data_reg)
dR_lmer <- data_reg$y_sim - predict(fit_sim, re.form=NA)
dS_lmer <- ranef(fit_sim)$stat$`(Intercept)`
```

Now, we fit the Inla models.
We fit the full model (fixed and random effects), a model on the total residuals, and a model on the site terms from the `lmer` fit.

``` {r sim-it-spatial-inla-fit, cache = TRUE}
#### full model
# create the stack
stk_spatial_stat <- inla.stack(
  data = list(y = data_reg$y_sim),
  A = list(A_stat, 1), 
  effects = list(idx_stat = idx_stat,
                 data_reg
  ))

fit_inla_spatial_stat <- inla(form_spatial_stat,
                              data = inla.stack.data(stk_spatial_stat),
                              control.predictor = list(A = inla.stack.A(stk_spatial_stat)),
                              family="gaussian",
                              control.family = list(hyper = prior_prec_phiSS),
                              control.inla = list(int.strategy = "eb", strategy = "gaussian"),
                              quantiles = c(0.05, 0.5, 0.95)
)

### ft from site terms
data_reg_stat <- data.frame(
  dS = dS_lmer,
  intercept = 1
)

# create the stack
stk_spatial_stat_u <- inla.stack(
  data = list(y = data_reg_stat$dS),
  A = list(A_stat_unique, 1), 
  effects = list(idx_stat = idx_stat,
                 data_reg_stat
  ))

fit_inla_spatial_stat_u <- inla(form_spatial_stat_u,
                                data = inla.stack.data(stk_spatial_stat_u),
                                control.predictor = list(A = inla.stack.A(stk_spatial_stat_u)),
                                family="gaussian",
                                control.family = list(hyper = prior_prec_phiS2S),
                                control.inla = list(int.strategy = "eb", strategy = "gaussian"),
                                quantiles = c(0.05, 0.5, 0.95)
)

#### fit from total residuals
data_reg$deltaR <- dR_lmer
# create the stack
stk_spatial_total <- inla.stack(
  data = list(y = data_reg$deltaR),
  A = list(A_stat, 1), 
  effects = list(idx_stat = idx_stat,
                 data_reg
  ))

fit_inla_spatial_total <- inla(form_spatial_total,
                               data = inla.stack.data(stk_spatial_total),
                               control.predictor = list(A = inla.stack.A(stk_spatial_total)),
                               family="gaussian",
                               control.family = list(hyper = prior_prec_phiSS),
                               control.inla = list(int.strategy = "eb", strategy = "gaussian"),
                               quantiles = c(0.05, 0.5, 0.95)
)
```

Below, we plot the posterior distributions of the spatial range as well as the associated standard deviation.

``` {r sim-it-spatial-results, out.width = '100%', fig.width=16}
p1 <- rbind(
  data.frame(inla.tmarginal(function(x) exp(x), 
                                fit_inla_spatial_stat$internal.marginals.hyperpar$`log(Range) for idx_stat`),
             mod = "full"),
  data.frame(inla.tmarginal(function(x) exp(x), 
                                fit_inla_spatial_stat_u$internal.marginals.hyperpar$`log(Range) for idx_stat`),
             mod = "dS"),
  data.frame(inla.tmarginal(function(x) exp(x), 
                                fit_inla_spatial_total$internal.marginals.hyperpar$`log(Range) for idx_stat`),
             mod = "dR")
) %>%
  ggplot() +
  geom_line(aes(x = x, y = y, color = mod), linewidth = 1.5) +
  geom_vline(xintercept = range, linewidth = 1.5) +
  labs(x = 'spatial range (km)', 'density') +
  theme(legend.position = c(0.8,0.8)) +
  guides(color = guide_legend(title = NULL))

p2 <- rbind(
  data.frame(inla.tmarginal(function(x) exp(x), 
                            fit_inla_spatial_stat$internal.marginals.hyperpar$`log(Stdev) for idx_stat`),
             mod = "full", type = 'phi_s2s_c'),
  data.frame(inla.tmarginal(function(x) exp(x), 
                            fit_inla_spatial_stat_u$internal.marginals.hyperpar$`log(Stdev) for idx_stat`),
             mod = "dS", type = 'phi_s2s_c'),
  data.frame(inla.tmarginal(function(x) exp(x), 
                            fit_inla_spatial_total$internal.marginals.hyperpar$`log(Stdev) for idx_stat`),
             mod = "dR", type = 'phi_s2s_c'),
  data.frame(inla.tmarginal(function(x) sqrt(exp(-x)), 
                            fit_inla_spatial_stat$internal.marginals.hyperpar$`Log precision for stat`),
             mod = "full", type = 'phi_s2s_0'),
  data.frame(inla.tmarginal(function(x) sqrt(exp(-x)), 
                            fit_inla_spatial_stat_u$internal.marginals.hyperpar$`Log precision for the Gaussian observations`),
             mod = "dS", type = 'phi_s2s_0'),
  data.frame(inla.tmarginal(function(x) sqrt(exp(-x)), 
                            fit_inla_spatial_total$internal.marginals.hyperpar$`Log precision for stat`),
             mod = "dR", type = 'phi_s2s_0')
) %>%
  ggplot() +
  geom_line(aes(x = x, y = y, color = mod, linetype = type), linewidth = 1.5) +
  geom_vline(xintercept = phi_s2s_c, linewidth = 1.5, linetype = 'dashed') +
  geom_vline(xintercept = phi_s2s_0, linewidth = 1.5) +
  labs(x = 'phi_S2S_c', 'density') +
  theme(legend.position = c(0.8,0.8)) +
  guides(color = guide_legend(title = NULL), linetype = guide_legend(title = NULL))

patchwork::wrap_plots(p1, p2)
```

We can see that the spatial range is quite well estimated for all approaches, and that the full model and the model based on total residuals give almost the same results.
The model based on site terms does not lead to good results for the standard deviations, in particular for $\phi_{S2S,c}$, which is severely underestimated.
The relative sizes of standard devations based on the fit from $\delta S$ are wrongly estimated.

## Cell-specific atteuation

In this section, we simulate data based on the cell-specific attenuation model [@Kuehn2019,@Dawood2013], and estimate the model parameters using the total model, as well as from within-event/within-site residuals.

Read in the cell-specific distances, and some definitions.

``` {r sim-it-cell-data}
# read in cell-specific attenuation
data_dm <- rstan::read_rdump(file.path('./Git/MixedModels_Biases/','/data','dm_25x25.Rdata'))
dm_sparse <- as(data_dm$RC,"dgCMatrix") / 100 # divide by 100 to avoid small values
n_cell <- data_dm$NCELL

prior_prec_cell    <- list(prec = list(prior = 'pc.prec', param = c(0.5, 0.01))) 
data_reg$idx_cell <- 1:n_rec
```

Now we define the parameters for the simulation, and sample.

``` {r sim-it-cell-sample}
tau_sim <- 0.17
phi_s2s_sim <- 0.2
phi_ss_sim <- 0.18
sigma_cell_sim <- 0.35

set.seed(5618)
dB_sim <- rnorm(n_eq, mean =0, sd = tau_sim)
dS_sim <- rnorm(n_stat, mean =0, sd =phi_s2s_sim)
dWS_sim <- rnorm(n_rec, mean = 0, sd = phi_ss_sim)
dC_sim <- rnorm(n_cell, mean = 0, sd = sigma_cell_sim)

data_reg$y_sim <- as.numeric(as.matrix(data_reg[,names_coeffs]) %*% coeffs + dm_sparse %*% dC_sim +
  dB_sim[eq] + dS_sim[stat] + dWS_sim)
```

Now we fit the different models using Inla.

```{r sim-cell-inla-fit}
# full fit
fit_sim_cell <- inla(y_sim ~ 0 + intercept + M1 + M2 + logR + MlogR + R + Fss + Frv + logVS +
                       f(eq, model = "iid", hyper = prior_prec_tau) + 
                       f(stat, model = "iid",hyper = prior_prec_phiS2S) +
                       f(idx_cell, model = "z", Z = dm_sparse, hyper = prior_prec_cell),
                     data = data_reg,
                     family="gaussian",
                     control.family = list(hyper = prior_prec_phiSS),
                     quantiles = c(0.05,0.5,0.95)
)

fit_sim <- lmer(y_sim ~ M1 + M2 + logR + MlogR + R + Fss + Frv + logVS + (1|eq) + (1|stat), data_reg)
data_reg$dWS_lmer <- data_reg$y_sim - predict(fit_sim)
fit_sim_cell_dws <- inla(dWS_lmer ~ 0 + intercept +
                            f(idx_cell, model = "z", Z = dm_sparse, hyper = prior_prec_cell),
                          data = data_reg,
                          family="gaussian",
                          control.family = list(hyper = prior_prec_phiSS),
                          quantiles = c(0.05,0.5,0.95)
)

# total residuals, but also take out linear R term
data_reg$dR_lmer <- data_reg$y_sim - (predict(fit_sim,re.form=NA) -
                           fixef(fit_sim)[6] * data_reg$R)

fit_sim_cell_dR <- inla(dR_lmer ~ 0 + intercept + R +
                          f(eq, model = "iid", hyper = prior_prec_tau) + 
                          f(stat, model = "iid",hyper = prior_prec_phiS2S) +
                          f(idx_cell, model = "z", Z = dm_sparse, hyper = prior_prec_cell),
                        data = data_reg,
                        family="gaussian",
                        control.family = list(hyper = prior_prec_phiSS),
                        quantiles = c(0.05,0.5,0.95)
)
```

Ths shows the posterior distribution of the standard deviation of the cell-specific attenuation coefficients, which is understimated from $\delta WS$.

``` {r sim-it-inla-results}
rbind(data.frame(inla.tmarginal(function(x) sqrt(exp(-x)), 
                                fit_sim_cell$internal.marginals.hyperpar$`Log precision for idx_cell`),
                 mod = "full"),
      data.frame(inla.tmarginal(function(x) sqrt(exp(-x)), 
                                fit_sim_cell_dws$internal.marginals.hyperpar$`Log precision for idx_cell`),
                 mod = "dWS"),
      data.frame(inla.tmarginal(function(x) sqrt(exp(-x)), 
                                fit_sim_cell_dR$internal.marginals.hyperpar$`Log precision for idx_cell`),
                 mod = "dR")
) %>%
  ggplot() +
  geom_line(aes(x = x, y = y, color = mod), linewidth = 1.5) +
  geom_vline(xintercept = sigma_cell_sim, linewidth = 1.5) +
  labs(x = 'sigma_cell', 'density') +
  theme(legend.position = c(0.8,0.8)) +
  guides(color = guide_legend(title = NULL))
```

# Plots of Repeated Simulations

In the paper, we show results from many repeated simulations, typically as density plots of estimated parameters.
The simulations are carried out using code as in this document, looping over the simulations and keeping the estimated parameters.
Here, we generate some of the plots of the paper.
Code to run the simulations can be found at <https://github.com/nikuehn/MixedModels_Biases/tree/main/r>.

## Simulations with Homoscedastic Standard Deviations

``` {r res-sim1-all}
# Results for simulations based on CB14 data
load(file = file.path('./Git/MixedModels_Biases/', 'results', 'results_sim1_CB.Rdata'))

# simulation
tau_sim <- 0.4
phi_s2s_sim <- 0.43
phi_ss_sim <- 0.5

# look at values of standard deviations estimated from lmer and Stan (using mean and median of posterior)
df <- data.frame(res_val) |>
  set_names(c('phis2s_lmer_mode','tau_lmer_mode','phiss_lmer_mode',
              'phis2s_stan_mean','tau_stan_mean','phiss_stan_mean',
              'phis2s_stan_median','tau_stan_median','phiss_stan_median'))
knitr::kable(head(df), digits = 5, row.names = TRUE,
             caption = "Comparison of standard deviation estimates.")
```


``` {r res-sim1-all-plots, out.width = '100%'}
p1 <- data.frame(res_val[,c(1,4,7)], res_sd[,c(1,4)]) %>%
  set_names(c('lmer_max', 'stan_mean','stan_median','lmer_sd(dS)','stan_sd(dS)')) %>%
  pivot_longer(everything(), names_sep = '_', names_to = c('model','type')) %>%
  ggplot() +
  geom_density(aes(x = value, color = model, linetype = type), linewidth = 1.5, key_glyph = draw_key_path) +
  labs(x = expression(paste(widehat(phi)[S2S]))) +
  guides(color = guide_legend(title = NULL), linetype = guide_legend(title = NULL)) +
  theme(legend.position = 'none',
        legend.key.width = unit(2,'cm')) +
  geom_vline(xintercept = phi_s2s_sim, linewidth = 1.5) +
  scale_linetype_manual(values = c(1,2,3,4),
                        labels = c('max','mean','median',TeX("sd($\\delta S$)"))) +
  scale_color_manual(values = c('red','blue'))

p2 <- data.frame(res_val[,c(2,5,8)], res_sd[,c(2,5)]) %>%
  set_names(c('lmer_max', 'stan_mean','stan_median','lmer_sd(dB)','stan_sd(dB)')) %>%
  pivot_longer(everything(), names_sep = '_', names_to = c('model','type')) %>%
  ggplot() +
  geom_density(aes(x = value, color = model, linetype = type), linewidth = 1.5, key_glyph = draw_key_path) +
  labs(x = expression(widehat(tau))) +
  guides(color = guide_legend(title = NULL), linetype = guide_legend(title = NULL)) +
  theme(legend.position = c(0.3,0.65),
        legend.key.width = unit(1.5,'cm')) +
  geom_vline(xintercept = tau_sim, linewidth = 1.5) +
  scale_linetype_manual(values = c(1,2,3,4),
                        labels = c('max','mean','median',TeX("sd($\\delta B$)"))) +
  scale_color_manual(values = c('red','blue'))

p3 <- data.frame(res_val[,c(3,6,9)], res_sd[,c(3,6)]) %>%
  set_names(c('lmer_max', 'stan_mean','stan_median','lmer_sd(dWS)','stan_sd(dWS)')) %>%
  pivot_longer(everything(), names_sep = '_', names_to = c('model','type')) %>%
  ggplot() +
  geom_density(aes(x = value, color = model, linetype = type), linewidth = 1.5, key_glyph = draw_key_path) +
  labs(x = expression(paste(widehat(phi)[SS]))) +
  guides(color = guide_legend(title = NULL), linetype = guide_legend(title = NULL)) +
  theme(legend.position = 'none',
        legend.key.width = unit(2,'cm')) +
  geom_vline(xintercept = phi_ss_sim, linewidth = 1.5) +
  scale_linetype_manual(values = c(1,2,3,4),
                        labels = c('max','mean','median',TeX("sd($\\delta WS$)"))) +
  scale_color_manual(values = c('red','blue'))

leg <- ggpubr::get_legend(p2)
patchwork::wrap_plots(p1,p2 + theme(legend.position = 'none'),p3,ggpubr::as_ggplot(leg), ncol = 2)
```


## Heteroscedastic Standard Deviations

``` {r res-sim2-hs-all}
# Results for simulations based on CB14 data
load(file = file.path('./Git/MixedModels_Biases/', 'results', 'results_sim2_heteroscedastic_coeff_CB.Rdata'))
load(file = file.path('./Git/MixedModels_Biases/', 'results', 'results_sim2_heteroscedastic_coeff_stan2_CB.Rdata'))

coeffs <- c(3.421046409, 0.193954090, -0.021982777, 0.287149291, -1.405635476, -0.002911264, -0.394575970)
names_coeffs <- c("intercept", "M1", "M2", "MlogR", "logR", "R", "logVS")

phi_s2s_sim <- 0.43
tau_sim_val <- c(0.4,0.25)
phi_sim_val <- c(0.55,0.4)
mb_tau <- c(5,6)
mb_phi <- c(4.5,5.5)
```

``` {r res-sim2-hs-all-plots, out.width = '100%'}
p1 <- data.frame(res_phi, res_phi_stan[,c(1,2)], res_phi_stan2[,c(1,2)]) %>%
  set_names(c('sd(dWS)_lowm','sd(dWS)+unc_lowm','sd(dWS)_largem','sd(dWS)+unc_largem',
              'stan_lowm','stan_largem','stanf_lowm','stanf_largem')) %>%
  pivot_longer(everything(), names_to = c('model','mag'),names_sep = '_') %>%
  ggplot() +
  geom_density(aes(x = value, color = model, linetype = mag), linewidth = lw, key_glyph = draw_key_path) +
  geom_vline(xintercept = phi_sim_val[2], linewidth = lw) +
  geom_vline(xintercept = phi_sim_val[1], linetype = 'dashed', linewidth = lw) +
  scale_color_manual(values = c('orange','red','blue','cyan'),
                     labels = c(TeX("sd(\\widehat{\\delta WS})"),
                                TeX("sd(\\widehat{\\delta WS} + unc)"),
                                TeX('stan ($\\delta R$)'), 'stan (full)')) +
  scale_linetype_manual(values = c(1,2),
                        labels = c(TeX(sprintf("$M \\geq %.1f$",mb_phi[2])), 
                                   TeX(sprintf("$M \\leq %.1f$",mb_phi[1])))) +
  guides(color = guide_legend(title = NULL), linetype = guide_legend(title = NULL)) +
  theme(legend.position = c(0.5,0.8),
        legend.key.width = unit(2,'cm')) +
  labs(x = expression(paste(widehat(phi)[SS]))) +
  lims(y = c(0,100))

p2 <- data.frame(res_tau, res_tau_stan[,c(1,2)], res_tau_stan2[,c(1,2)]) %>%
  set_names(c('sd(dB)_lowm','sd(dB)+unc_lowm','sd(dB)_largem','sd(dB)+unc_largem',
              'stan_lowm','stan_largem','stanf_lowm','stanf_largem')) %>%
  pivot_longer(everything(), names_to = c('model','mag'),names_sep = '_') %>%
  ggplot() +
  geom_density(aes(x = value, color = model, linetype = mag), linewidth = lw, key_glyph = draw_key_path) +
  geom_vline(xintercept = tau_sim_val[2], linewidth = lw) +
  geom_vline(xintercept = tau_sim_val[1], linetype = 'dashed', linewidth = lw) +
  scale_color_manual(values = c('orange','red','blue','cyan'),
                     labels = c(TeX("sd(\\widehat{\\delta B})"),
                                TeX("sd(\\widehat{\\delta B} + unc)"),
                                TeX('stan ($\\delta R$)'), 'stan (full)')) +
  scale_linetype_manual(values = c(1,2),
                        labels = c(TeX(sprintf("$M \\geq %.1f$",mb_tau[2])), 
                                   TeX(sprintf("$M \\leq %.1f$",mb_tau[1])))) +
  guides(color = guide_legend(title = NULL), linetype = guide_legend(title = NULL)) +
  theme(legend.position = 'none') +
  labs(x = expression(paste(widehat(tau))))

p3 <- data.frame(res_phis2s[,c(1,3)], res_phis2s_stan2[,1]) %>%
  set_names(c('lmer','stan','stanf')) %>%
  pivot_longer(everything()) %>%
  ggplot() +
  geom_density(aes(x = value, color = name), linewidth = lw, key_glyph = draw_key_path) +
  geom_vline(xintercept = phi_s2s_sim, linewidth = lw) +
  scale_color_manual(values = c('red','blue','cyan'),
                     labels = c('lmer', TeX('stan ($\\delta R$)'), 'stan (full')) +
  guides(color = guide_legend(title = NULL)) +
  theme(legend.position = 'none') +
  labs(x = expression(paste(widehat(phi)[S2S])))

leg <- ggpubr::get_legend(p1)
patchwork::wrap_plots(p1 + theme(legend.position = 'none'),p2,p3,ggpubr::as_ggplot(leg), ncol = 2)
```

``` {r res-sim2-hs-all-plots-coeffs, out.width = '100%'}
df1 <- data.frame(res_coeffs) %>% set_names(names_coeffs)
df1$model <- 'lmer'

df2 <- data.frame(res_coeffs_stan2) %>% set_names(names_coeffs)
df2$model <- 'stan'

df <- data.frame(name = names_coeffs,
                true = coeffs)

rbind(df1 %>% pivot_longer(!model),
      df2 %>% pivot_longer(!model)) %>%
  ggplot() +
  geom_density(aes(x = value, color = model), linewidth = 1.5, key_glyph = draw_key_path) +
  facet_wrap(vars(name), scales = "free") +
  geom_vline(aes(xintercept = true), data = df, linewidth = 1.5) +
  guides(color = guide_legend(title = NULL)) +
  labs(x = '') +
  theme(legend.position = c(0.8,0.2))
```

## $V_{S30}$-Scaling from Site Terms

Here, we show results of estimating the coefficient for the $V_{S30}$-scaling from the full model, site terms, and a mixed-effects regression of total residuals.
We performed the repeated simulations for both the CB141 data and the Ialian data, and below we show results for both.
We see very similar results, with a larger bias for the estimaton from well-recorded stations (more than 9 records) for the Italian data.
There are less such stations in the Italian data set, which results in this larger bias.
This is a reminder that the size of the biases that can occur depends on the data set.

``` {r plot-vs, out.width = '100%', fig.width=12}
set1 <- RColorBrewer::brewer.pal(7, "Set1")
coeff_vs <- -0.394575970

# Results for simulations based on CB14 data
load(file = file.path('./Git/MixedModels_Biases/', 'results', 'res_vs_ita18_CB.Rdata'))
xlab <- expression(paste(c[vs]))
names <- c('full','dS','dS(N>10)','dR')
df <- data.frame(res_val[,c(1,5,10,15)]) %>% set_names(names) %>%
  pivot_longer(everything())
df$name <- factor(df$name, names)

p1 <- ggplot(df) +
  geom_density(aes(x = value, color = name), linewidth = 1.5, key_glyph = draw_key_path) +
  geom_vline(xintercept = coeff_vs, linewidth = 1.5) +
  scale_color_manual(values=set1,
                     labels = c('full',TeX('$\\widehat{\\delta S}$'),
                                TeX('$\\widehat{\\delta S}$ ($N \\geq 10$)'),
                                TeX('$\\widehat{\\delta R}$'))) +
  guides(color = guide_legend(title=NULL)) +
  labs(x = xlab, title = 'CB14 Data') +
  theme(legend.position = c(0.2,0.8))


# Results for simulations based on Italian
load(file = file.path('./Git/MixedModels_Biases/', 'results', 'res_vs_ita18_italy.Rdata'))
xlab <- expression(paste(c[vs]))
names <- c('full','dS','dS(N>10)','dR')
df <- data.frame(res_val[,c(1,5,10,15)]) %>% set_names(names) %>%
  pivot_longer(everything())
df$name <- factor(df$name, names)

p2 <- ggplot(df) +
  geom_density(aes(x = value, color = name), linewidth = 1.5, key_glyph = draw_key_path) +
  geom_vline(xintercept = coeff_vs, linewidth = 1.5) +
  scale_color_manual(values=set1,
                     labels = c('full',TeX('$\\widehat{\\delta S}$'),
                                TeX('$\\widehat{\\delta S}$ ($N \\geq 10$)'),
                                TeX('$\\widehat{\\delta R}$'))) +
  guides(color = guide_legend(title=NULL)) +
  labs(x = xlab, title = 'Italian Data') +
  theme(legend.position = c(0.2,0.8))

patchwork::wrap_plots(p1, p2)
```

## Correlations

``` {r res-sim4-corr-all}
# Results for simulations based on CB14 data
df_res_cor <- read.csv(file.path('./Git/MixedModels_Biases/', 'results',
                                        'res_sim_cor_CB_N50.csv'))

tau_sim <- 0.4
phi_s2s_sim <- 0.43
phi_ss_sim <- 0.5

rho <- 0.7
tau2 <- 1

df_res_cor %>% pivot_longer(c(cor_sim, cor_lme, cor_mean)) %>%
  ggplot() +
  geom_density(aes(x = value, color = name), linewidth = lw, key_glyph = draw_key_path) +
  geom_vline(aes(xintercept = rho), linewidth = lw) +
  scale_color_manual(values=c("blue", 'red', 'gray'),
                     labels=c("2-step lmer", "1-step stan", "sim")
  ) +
  guides(color = guide_legend(title=NULL)) +
  theme(legend.position = c(0.18,0.89)) +
  labs(x = expression(widehat(rho)))
```


## Spatial Correlations of Site Terms

``` {r res-sim5-spatial-all, out.width = '100%'}
seed <- 1701
load(file = file.path('./Git/MixedModels_Biases/', 'results', sprintf('res_spatial_ita18_italy_seed%d.Rdata', seed)))
load(file = file.path('./Git/MixedModels_Biases/', 'results', sprintf('res_spatial_ita18b_italy_seed%d.Rdata', seed)))


range <- 30
wvar <- 0.65
tau_sim <- 0.17
phi_s2s_sim <- 0.23
phi_s2s_0 <- sqrt((1 - wvar) * phi_s2s_sim^2)
phi_s2s_c <- sqrt(wvar * phi_s2s_sim^2)
phi_ss_sim <- 0.2

p1 <- data.frame(res_spatial[,c(4,7)],res_spatial_tot[,4]) %>% set_names('m1','m3','m2') %>%
  pivot_longer(everything()) %>%
  ggplot() +
  geom_density(aes(x = value, color = name), linewidth = lw, key_glyph = draw_key_path) +
  geom_vline(aes(xintercept = range), linewidth = lw) +
  labs(x = 'spatial range (km)') +
  theme(legend.position = c(0.85,0.85)) +
  guides(color = guide_legend(title=NULL)) +
  scale_color_manual(values = c('blue','red','orange'),
                     labels = c('full',
                                TeX("$\\widehat{\\delta R}$"),
                                TeX("$\\widehat{\\delta S}$")))

p2 <- data.frame(m1 = res_spatial[,5]^2 / (1/res_spatial[,3] + res_spatial[,5]^2),
                 m1 = res_spatial_tot[,5]^2 / (1/res_spatial_tot[,3] + res_spatial_tot[,5]^2),
                 m3 = res_spatial[,8]^2 / (1/res_spatial[,6] + res_spatial[,8]^2)) %>%
  pivot_longer(everything()) %>%
  ggplot() +
  geom_density(aes(x = value, color = name), linewidth = 1.5, key_glyph = draw_key_path) +
  geom_vline(aes(xintercept = wvar), linewidth = 1.5) +
  labs(x = TeX("$\\hat{\\phi}_{S2S,c}^2 / \\hat{phi}_{S2S}^2$")) +
  theme(legend.position = 'none') +
  guides(color = guide_legend(title=NULL)) +
  scale_color_manual(values = c('blue','red','orange'),
                     labels = c('full',
                                TeX("$\\widehat{\\delta R}$"),
                                TeX("$\\widehat{\\delta S}$")))

p3 <- data.frame(res_spatial[,c(5,8)],res_spatial_tot[,5]) %>% set_names('m1','m3','m2') %>%
  pivot_longer(everything()) %>%
  ggplot() +
  geom_density(aes(x = value, color = name), linewidth = lw, key_glyph = draw_key_path) +
  geom_vline(aes(xintercept = phi_s2s_c), linewidth = lw) +
  labs(x = TeX("$\\hat{\\phi}_{S2S,c}$")) +
  theme(legend.position = 'none') +
  guides(color = guide_legend(title=NULL)) +
  scale_color_manual(values = c('blue','red','orange'),
                     labels = c('full',
                                TeX("$\\widehat{\\delta R}$"),
                                TeX("$\\widehat{\\delta S}$")))

p4 <- data.frame(1/sqrt(res_spatial[,c(3,6)]),1/sqrt(res_spatial_tot[,3])) %>% set_names('m1','m3','m2') %>%
  pivot_longer(everything()) %>%
  ggplot() +
  geom_density(aes(x = value, color = name), linewidth = lw, key_glyph = draw_key_path) +
  geom_vline(aes(xintercept = phi_s2s_0), linewidth = lw) +
  labs(x = TeX("$\\hat{\\phi}_{S2S,0}$")) +
  theme(legend.position = 'none') +
  guides(color = guide_legend(title=NULL)) +
  scale_color_manual(values = c('blue','red','orange'),
                     labels = c('full',
                                TeX("$\\widehat{\\delta R}$"),
                                TeX("$\\widehat{\\delta S}$")))

patchwork::wrap_plots(p1,p2,p3,p4, ncol = 2)
```

## Cell-Specific Attenuation

``` {r res-sim6-cell-all, out.width = '100%'}
tau <- 0.17
phi_s2s <- 0.2
phi_0 <- 0.18
sigma_cell <- 0.35

seed <- 5618
load(file = file.path('./Git/MixedModels_Biases/', 'results',
                      sprintf('res_cell_italy_seed%d.Rdata', seed)))

p1 <- data.frame(res_cell[,c(4,10,6)]) %>% set_names(c('full','dR','dWS')) %>%
  pivot_longer(everything()) %>%
  ggplot() +
  geom_density(aes(x = value, color = name), linewidth = 1.5, key_glyph = draw_key_path) +
  geom_vline(aes(xintercept = sigma_cell), linewidth = 1.5) +
  labs(x = expression(paste(sigma[cell]))) +
  theme(legend.position = c(0.5,0.85)) +
  guides(color = guide_legend(title=NULL)) +
  scale_color_manual(values = c('red','orange','blue'),
                     labels = c(TeX("$\\delta R$"), TeX("$\\widehat{\\delta WS}$"), "full"))

p2 <- data.frame(res_cell_fix[,c(1,7,4)]) %>% set_names(c('full','dR','dWS')) %>%
  pivot_longer(everything()) %>%
  ggplot() +
  geom_density(aes(x = value, color = name), linewidth = lw, key_glyph = draw_key_path) +
  geom_vline(aes(xintercept = coeffs_sim[6]), linewidth = lw) +
  labs(x = expression(paste(c[attn]))) +
  theme(legend.position = 'none') +
  guides(color = guide_legend(title=NULL)) +
  scale_color_manual(values = c('red','orange','blue'),
                     labels = c(TeX("$\\delta R$"), TeX("$\\widehat{\\delta WS}$"), "full"))

p3 <- data.frame(full = res_cell[,1]^2/res_cell_sdlme[,3]^2,
                 dR = res_cell[,7]^2/res_cell_sdlme[,3]^2,
                 dS = res_cell[,5]^2/res_cell_sdlme[,3]^2) %>%
  pivot_longer(everything()) %>%
  ggplot() +
  geom_density(aes(x = value, color = name), linewidth = 1.5) +
  labs(x = TeX("$\\hat{\\phi}_{SS,0}^2 / \\hat{\\phi}_{SS}^2$")) +
  theme(legend.position = 'none') +
  guides(color = guide_legend(title=NULL)) +
  scale_color_manual(values = c('red','orange','blue'),
                     labels = c(TeX("$\\delta R$"), TeX("$\\widehat{\\delta WS}$"), "full"))

p4 <- data.frame(res_cell_cor[,c(4,6,5)]) %>%
  set_names(c('full','dR','dWS')) %>%
  pivot_longer(everything()) %>%
  ggplot() +
  geom_density(aes(x = value, color = name), linewidth = 1.5) +
  labs(x = expression(paste(rho,'(c'[true],',c'[est],')'))) +
  theme(legend.position = 'none') +
  guides(color = guide_legend(title=NULL)) +
  scale_color_manual(values = c('red','orange','blue'),
                     labels = c(TeX("$\\delta R$"), TeX("$\\widehat{\\delta WS}$"), "full"))

patchwork::wrap_plots(p1,p2,p3,p4, ncol = 2)
```

# References
